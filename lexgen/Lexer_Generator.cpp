#include "Lexer_Generator.h"
#include <filesystem>
#include <fstream>
#include <iostream>

void Lexer_Generator::write() const {
  std::ofstream ofile(_outdir + "lexer.cpp");

  ofile << "#include <fstream>\n"
           "#include <iostream>\n"
           "#include <string>\n"
           "#include <unordered_map>\n"
           "#include <utility>\n"
           "#include <vector>\n\n";

  // clang-format off
  ofile <<
  "using value = uint64_t;\n"
  "\n"
  "//***************** BEGIN ENUM TOKEN_TYPE ************************************//\n"
  "enum class Token_Type {\n"
  "  NILL,\n"
  "  ezEOF\n"
  "};\n"
  "//***************** END ENUM TOKEN_TYPE **************************************//\n"
  "\n"
  "//***************** BEGIN CLASS DEFINITION TOKEN *****************************//\n"
  "\n"
  "class Token {\n"
  " public:\n"
  "  explicit Token(Token_Type const &token = Token_Type::NILL,\n"
  "                 std::string lexeme = \"\", std::string content = \"\",\n"
  "                 value line = 1);\n"
  "  [[nodiscard]] std::string to_string() const;\n"
  "  [[nodiscard]] Token_Type const &token_type() const { return _token_type; }\n"
  "  [[nodiscard]] std::string const &lexeme() const { return _lexeme; }\n"
  "  [[nodiscard]] value const &line() const { return _line; }\n"
  "\n"
  " private:\n"
  "  Token_Type _token_type;\n"
  "  std::string _lexeme;\n"
  "  std::string _content;\n"
  "  value _line;\n"
  "};\n"
  "//***************** END CLASS DEFINITION TOKEN *******************************//\n"
  "\n"
  "//***************** BEGIN CLASS IMPLEMENTATION TOKEN *************************//\n"
  "\n"
  "Token::Token(Token_Type const &token, std::string lexeme, std::string content,\n"
  "           value const line)\n"
  "  : _token_type(token), _lexeme(std::move(lexeme)),\n"
  "    _content(std::move(content)), _line(line) {}\n"
  "\n"
  "std::string Token::to_string() const {\n"
  "  if (_token_type != Token_Type::ezEOF) {\n"
  "    return _lexeme + \" \" + _content + \" \" + \"line \" + std::to_string(_line);\n"
  "  }\n"
  "  return \"\";\n"
  "}\n"
  "//***************** END CLASS IMPLEMENTATION TOKEN ***************************//\n"
  "\n"
  "//***************** BEGIN CLASS DEFINITION LEXER *****************************//\n"
  "\n"
  "class Lexer {\n"
  " public:\n"
  "  explicit Lexer(std::string str = \"\");\n"
  "  std::vector<Token> lex_tokens();\n"
  "  std::vector<Token> lex_tokens(std::string str);\n"
  "  std::vector<Token> lex_tokens(std::vector<std::string> strings);\n"
  "\n"
  "  static std::unordered_map<std::string, Token_Type> keywords;\n"
  "\n"
  " private:\n"
  "  std::string _str;\n"
  "  value _start{};             ///< first character of current lexeme\n"
  "  value _current{};           ///< character currently being considered\n"
  "  value _line = 1;            ///< current token line\n"
  "  std::vector<Token> _tokens; ///< list of tokens\n"
  "\n"
  "  void lex_token();\n"
  "  [[nodiscard]] bool is_at_end() const;\n"
  "  void push_token(Token_Type token, const std::string &content = \"\");\n"
  "  void number();\n"
  "  void keyword_or_id();\n"
  "};\n"
  "//***************** END CLASS DEFINITION LEXER *******************************//\n"
  "\n"
  "//***************** BEGIN CLASS IMPLEMENTATION LEXER *************************//\n"
  "\n"
  "Lexer::Lexer(std::string str) : _str(std::move(str)) {}\n"
  "\n"
  "std::unordered_map<std::string, Token_Type> Lexer::keywords = {\n"
  "\n"
  "};\n"
  "std::vector<Token> Lexer::lex_tokens(std::vector<std::string> strings) {\n"
  "  std::vector<std::vector<Token>> tmp;\n"
  "  for (auto const &str : strings) {\n"
  "    tmp.push_back(lex_tokens(str));\n"
  "    // the way it is set up now, at the end of each string an ezEOF token is\n"
  "    // added to the token list. Fine, however, that wont' work if we are trying\n"
  "    // to parse more than one string. So, ... pop_back() :-)\n"
  "    // not the best solution, but it'll work for now\n"
  "    if (str != strings.back()) {\n"
  "      tmp.back().pop_back();\n"
  "    }\n"
  "  }\n"
  "  _tokens.clear();\n"
  "  for (auto const &v : tmp) {\n"
  "    for (auto const &t : v) {\n"
  "      _tokens.push_back(t);\n"
  "    }\n"
  "  }\n"
  "  return _tokens;\n"
  "}\n"
  "\n"
  "std::vector<Token> Lexer::lex_tokens(std::string str) {\n"
  "  _start = _current = 0;\n"
  "  _str = std::move(str);\n"
  "  _tokens.clear();\n"
  "  return lex_tokens();\n"
  "}\n"
  "\n"
  "std::vector<Token> Lexer::lex_tokens() {\n"
  "  while (!is_at_end()) {\n"
  "    _start = _current; // move to start of next lexeme\n"
  "    lex_token();\n"
  "  }\n"
  "  // final EOF token\n"
  "  _tokens.emplace_back(Token_Type::ezEOF, \"\", \"\", _line);\n"
  "  return _tokens;\n"
  "}\n"
  "\n"
  "void Lexer::lex_token() {\n"
  "  using tt = Token_Type;\n"
  "  switch (unsigned char const ch = _str[_current++]) {\n"
  "  }\n"
  "}\n"
  "\n"
  "bool Lexer::is_at_end() const { return _current >= _str.length(); }\n"
  "\n"
  "void Lexer::push_token(Token_Type token, std::string const &content) {\n"
  "  _tokens.emplace_back(token, _str.substr(_start, _current - _start), content,\n"
  "                       _line);\n"
  "}\n"
  "//***************** END CLASS IMPLEMENTATION LEXER ***************************//\n"
  "\n"
  "//***************** BEGIN MAIN ***********************************************//\n"
  "\n"
  "void run_file(std::string const &file_name);\n"
  "void run_repl();\n"
  "void run(std::string const &str);\n"
  "\n"
  "int main(const int argc, const char *argv[]) {\n"
  "  if (argc > 2) {\n"
  "    std::cout << \"To tokenize a file : ./hatchling [file]\\n\";\n"
  "    std::cout << \"To enter REPL mode: ./hatchling\\n\";\n"
  "  } else if (argc > 1) {\n"
  "    run_file(argv[1]);\n"
  "  } else {\n"
  "    run_repl();\n"
  "  }\n"
  "  return EXIT_SUCCESS;\n"
  "}\n"
  "\n"
  "void run_file(std::string const &file_name) {\n"
  "  std::ifstream ifstream(file_name);\n"
  "  try {\n"
  "    if (!ifstream.is_open()) {\n"
  "      throw std::runtime_error(file_name + \" not found\\n\");\n"
  "    }\n"
  "  } catch ([[maybe_unused]] std::runtime_error &e) {\n"
  "    std::cerr << \"Failed to open file: \" << e.what() << \'\\n\';\n"
  "  }\n"
  "  std::vector<std::string> strings{};\n"
  "  std::string str;\n"
  "  while (std::getline(ifstream, str)) {\n"
  "    strings.push_back(str);\n"
  "  }\n"
  "  Lexer lexer;\n"
  "  lexer.lex_tokens(strings);\n"
  "}\n"
  "\n"
  "void run_repl() {\n"
  "  std::string str;\n"
  "  std::cout << \"> \";\n"
  "  while (std::getline(std::cin, str)) {\n"
  "    run(str);\n"
  "    std::cout << \"\\n> \";\n"
  "  }\n"
  "}\n"
  "\n"
  "void run(std::string const &str) {\n"
  "  for (Lexer lexer(str); auto const &token : lexer.lex_tokens()) {\n"
  "    std::cout << token.to_string();\n"
  "  }\n"
  "}\n"
  "//****************** END MAIN ************************************************//\n";

  // clang-format on
}